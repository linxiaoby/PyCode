{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nonsense?  kiss off, geek. what I said is true.  I'll have your account terminated.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "#读入数据\n",
    "import pandas as pd\n",
    "dataPath = \"D:\\\\AllCode\\Datas\\\\Kaggle\\\\Toxic\\\\\"\n",
    "train = pd.read_csv(dataPath + \"train.csv\\\\train.csv\")\n",
    "test = pd.read_csv(dataPath + \"test.csv\\\\test.csv\")\n",
    "test_id = test[\"id\"]\n",
    "train = train.drop([\"id\"], axis=1)\n",
    "test = test.drop([\"id\"], axis=1)\n",
    "print (train.columns.values)\n",
    "\n",
    "train = train.iloc[:200,:] #取200条测试程序 \n",
    "test = test.iloc[:20, :]#取20条测试程序\n",
    "\n",
    "fulldata = pd.concat([train, test], axis=0, ignore_index = True)\n",
    "fulldata = fulldata.drop(['identity_hate', 'insult', 'obscene', \n",
    "                          'severe_toxic', 'threat', 'toxic'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        comment_text\n0    nonsense kiss geek said true account terminated\n1  please vandalize pages edit w merwin continue ...\n2  points interest removed points interest sectio...\n3  asking nationality racial offence wow aware bl...\n4  reader going say ethereal vocal style dark lyr...\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "#数据预处理\n",
    "import re\n",
    "#大写转为小写\n",
    "m = fulldata.shape[0]\n",
    "fulldata[\"comment_text\"] = fulldata[\"comment_text\"].str.lower()\n",
    "\n",
    "#去除无用的符号用空格代替 ? , , \\n .\n",
    "#去除停用词\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "for i in range(5):\n",
    "    tmp = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！,.？?、~@#￥%……&*（）]\", \n",
    "                                         \" \",str(fulldata[\"comment_text\"][i]))\n",
    "    fulldata[\"comment_text\"][i] = ' '.join([word for word in tmp.split() \n",
    "                                         if word not in (stopwords.words('english'))])\n",
    "print fulldata.head()\n",
    "\n",
    "\n",
    "\n",
    "#向量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        comment_text\n0   the reader here is not go by my say so for et...\n1   the reader here is not go by my say so for et...\n2   the reader here is not go by my say so for et...\n3   the reader here is not go by my say so for et...\n4   the reader here is not go by my say so for et...\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "for i in range(1):\n",
    "    tmp1 = \"\"\n",
    "    for word in fulldata[\"comment_text\"][i].split():\n",
    "        tmp1= tmp1 + \" \" + porter_stemmer.stem(word) #波特词干算法分词器\n",
    "    fulldata[\"comment_text\"][i] = tmp1\n",
    "print fulldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#向量化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
